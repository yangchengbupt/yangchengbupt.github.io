import re
import json
import os
import random

# add some new things for extracting selected publications and get the shieldio data

def clean_title(title):
    """
    å¦‚æœæ ‡é¢˜ä»¥ (xxxx) å¼€å¤´ï¼Œåˆ™ç§»é™¤è¯¥éƒ¨åˆ†ï¼Œå¹¶å»é™¤ ')' åçš„ç©ºæ ¼ã€‚
    
    å‚æ•°:
        title (str): åŸå§‹æ ‡é¢˜ã€‚
        
    è¿”å›:
        str: æ¸…ç†åçš„æ ‡é¢˜ã€‚
    """
    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä»¥ (xxxx) å¼€å¤´çš„æ¨¡å¼
    pattern = r'^\([^\)]+\)\s*'
    cleaned_title = re.sub(pattern, '', title)
    return cleaned_title

def read_titles(filename):
    # ä»csvæ–‡ä»¶ä¸­è¯»å–æ ‡é¢˜ï¼Œæ ‡é¢˜æ˜¯ç¬¬äºŒåˆ—ï¼Œä»ç¬¬äºŒè¡Œå¼€å§‹
    titles = []
    with open (filename, 'r') as file:
        lines = file.readlines()
        for line in lines[1:]:
            title = line.split(',')[1]
            titles.append(title)
    return titles

def read_long_ids_2024_before(filename):
    # ä»csvæ–‡ä»¶ä¸­è¯»å–æ ‡é¢˜ï¼Œæ ‡é¢˜æ˜¯ç¬¬äºŒåˆ—ï¼Œä»ç¬¬äºŒè¡Œå¼€å§‹
    long_ids = []
    with open (filename, 'r') as file:
        lines = file.readlines()
        for line in lines[1:]:
            long_id = line.split(',')[2]
            year = line.split(',')[4]
            if year < '2024':
                long_ids.append(long_id)
    return long_ids

def read_long_ids_2024_and_now(filename):
    # ä»csvæ–‡ä»¶ä¸­è¯»å–æ ‡é¢˜ï¼Œæ ‡é¢˜æ˜¯ç¬¬äºŒåˆ—ï¼Œä»ç¬¬äºŒè¡Œå¼€å§‹
    long_ids = []
    with open (filename, 'r') as file:
        lines = file.readlines()
        for line in lines[1:]:
            long_id = line.split(',')[2]
            year = line.split(',')[4]
            if year == '2024':
                long_ids.append(long_id)
    return long_ids

def extract_titles(markdown_content):
    """
    ä»ç»™å®šçš„ Markdown å†…å®¹ä¸­æå– '## ğŸ”– Selected Publications' éƒ¨åˆ†çš„å‡ºç‰ˆç‰©æ ‡é¢˜ï¼Œå¹¶è¿›è¡Œæ¸…ç†ã€‚
    
    å‚æ•°:
        markdown_content (str): Markdown æ–‡ä»¶çš„å†…å®¹ã€‚
    
    è¿”å›:
        list: æå–å¹¶æ¸…ç†åçš„æ ‡é¢˜åˆ—è¡¨ã€‚
    """
    titles = []
    in_selected_publications = False
    extract_next_line = False  # æ ‡å¿—æ˜¯å¦éœ€è¦æå–ä¸‹ä¸€è¡Œçš„æ ‡é¢˜

    # æŒ‰è¡Œåˆ†å‰²å†…å®¹
    lines = markdown_content.split('\n')
    
    for line_number, line in enumerate(lines, 1):
        # æ£€æŸ¥æ˜¯å¦è¿›å…¥ '## ğŸ”– Selected Publications' éƒ¨åˆ†
        if not in_selected_publications:
            # # ğŸ“ Publications
            if re.match(r'^#\s*ğŸ“\s*Publications', line):
                in_selected_publications = True
                # print(f"è¿›å…¥ 'Selected Publications' éƒ¨åˆ† (ç¬¬ {line_number} è¡Œ)")
            continue
        else:
            # å¦‚æœé‡åˆ°æ–°çš„æ ‡é¢˜ï¼ˆä»¥ '#' å¼€å¤´ï¼‰ï¼Œåˆ™é€€å‡º
            if re.match(r'^#\s*ğŸ–\s*Honors\s*and\s*Awards', line):
                # print(f"é‡åˆ°æ–°æ ‡é¢˜ï¼Œåœæ­¢æå– (ç¬¬ {line_number} è¡Œ)")
                break
            
            # æ£€æŸ¥å½“å‰è¡Œæ˜¯å¦ä»¥ '-', '*', '+' å¼€å¤´
            if re.match(r'^[\-\*\+]\s+', line):
                extract_next_line = True
                # print(f"æ‰¾åˆ°ä»¥ '-', '*', æˆ– '+' å¼€å¤´çš„è¡Œ (ç¬¬ {line_number} è¡Œ)ï¼Œå‡†å¤‡æå–ä¸‹ä¸€è¡Œçš„æ ‡é¢˜")
                continue  # ç»§ç»­åˆ°ä¸‹ä¸€è¡Œ

            # å¦‚æœæ ‡å¿—ä¸ºéœ€è¦æå–ä¸‹ä¸€è¡Œçš„æ ‡é¢˜
            if extract_next_line:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ–¹æ‹¬å·ä¸­çš„å†…å®¹
                match = re.search(r'\[([^\]]+)\]\([^)]+\)', line)
                if match:
                    title = match.group(1).strip()
                    # æ¸…ç†æ ‡é¢˜
                    # cleaned_title = clean_title(title)
                    titles.append(title)
                    # print(f"æå–å¹¶æ¸…ç†æ ‡é¢˜: {cleaned_title} (ç¬¬ {line_number} è¡Œ)")
                # else:
                #     print(f"ç¬¬ {line_number} è¡Œæœªæ‰¾åˆ°åŒ¹é…çš„æ ‡é¢˜æ ¼å¼")
                extract_next_line = False  # é‡ç½®æ ‡å¿—

    return titles

def find_citations_by_long_id(data, target_long_id):
    """
    ä»Google Scholaræ•°æ®ä¸­æŸ¥æ‰¾æŒ‡å®šé•¿IDè®ºæ–‡çš„å¼•ç”¨æ•°é‡
    
    å‚æ•°:
    data (dict): Google Scholaræ•°æ®å­—å…¸
    target_long_id (str): è¦æŸ¥æ‰¾çš„è®ºæ–‡é•¿ID
    
    è¿”å›:
    tuple: (å¼•ç”¨æ•°é‡, è®ºæ–‡ID) å¦‚æœæ‰¾åˆ°è®ºæ–‡ï¼Œå¦åˆ™è¿”å› (None, None)
    """
    # éå†publicationså­—å…¸
    for paper_id, paper_info in data['publications'].items():
        # è·å–å½“å‰è®ºæ–‡é•¿ID
        current_long_id = paper_info['author_pub_id']
        
        # æ¯”è¾ƒé•¿ID
        if current_long_id == target_long_id:
            return paper_info['num_citations'], paper_id
    
    return None, None

def find_citations_by_title(data, target_title):
    """
    ä»Google Scholaræ•°æ®ä¸­æŸ¥æ‰¾æŒ‡å®šæ ‡é¢˜è®ºæ–‡çš„å¼•ç”¨æ•°é‡
    
    å‚æ•°:
    data (dict): Google Scholaræ•°æ®å­—å…¸
    target_title (str): è¦æŸ¥æ‰¾çš„è®ºæ–‡æ ‡é¢˜
    
    è¿”å›:
    tuple: (å¼•ç”¨æ•°é‡, è®ºæ–‡ID) å¦‚æœæ‰¾åˆ°è®ºæ–‡ï¼Œå¦åˆ™è¿”å› (None, None)
    """
    # è½¬æ¢ç›®æ ‡æ ‡é¢˜ä¸ºå°å†™ï¼Œç”¨äºä¸åŒºåˆ†å¤§å°å†™çš„æ¯”è¾ƒ
    target_title = target_title.lower().strip()
    
    # éå†publicationså­—å…¸
    for paper_id, paper_info in data['publications'].items():
        # è·å–å½“å‰è®ºæ–‡æ ‡é¢˜å¹¶è½¬æ¢ä¸ºå°å†™
        current_title = paper_info['bib']['title'].lower().strip()
        
        # æ¯”è¾ƒæ ‡é¢˜
        if current_title == target_title:
            return paper_info['num_citations'], paper_id
    
    return None, None

# å‡è®¾æ‚¨çš„ Markdown æ–‡ä»¶åä¸º 'publications.md'
# markdown_file = '../_pages/about.md'

# try:
#     # è¯»å– Markdown æ–‡ä»¶å†…å®¹
#     with open(markdown_file, 'r', encoding='utf-8') as file:
#         content = file.read()
#     print("Markdown æ–‡ä»¶å·²æˆåŠŸè¯»å–ã€‚\n")
# except FileNotFoundError:
#     print(f"æ–‡ä»¶ '{markdown_file}' æœªæ‰¾åˆ°ã€‚è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
#     exit(1)
# except Exception as e:
#     print(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
#     exit(1)

def title_citations():

    # æå–å¹¶æ¸…ç†æ ‡é¢˜
    # publication_titles = extract_titles(content)

    publication_titles = read_titles('results/all_publications.csv')
    # print(test_titles)

    json_file = f'results/gs_data.json'
    selected_data = json.load(open(json_file, 'r'))

    for title in publication_titles:
        cleaned_title = clean_title(title)
        
        if title == cleaned_title:
        # æå–ç¬¬ä¸€ä¸ªå•è¯ä½œä¸ºå…³é”®å­—
            keyword = cleaned_title.split()[0]
        else:
        # æå–æ²¡æ¸…ç†å‰çš„ç¬¬ä¸€ä¸ª()ä¸­çš„å†…å®¹ä½œä¸ºå…³é”®å­—
            keyword = title.split()[0]
        # å»é™¤æ‹¬å·
        keyword = keyword[1:-1]
        # print(f"æå–å¹¶æ¸…ç†æ ‡é¢˜: {cleaned_title}ï¼Œå…³é”®å­—: {keyword}")
        
        # åœ¨resultsæ–‡ä»¶å¤¹ä¸‹åˆ›å»ºselected_pubsæ–‡ä»¶å¤¹ï¼Œå¦‚æœä¸å­˜åœ¨
        if not os.path.exists('results/selected_pubs'):
            os.makedirs('results/selected_pubs')
        
        citations, paper_id = find_citations_by_title(selected_data, cleaned_title)
        
        # print(paper_id)
        
        # paper_idé‡Œé¢æœ‰ä¸€ä¸ª:ï¼Œåªéœ€è¦åé¢çš„éƒ¨åˆ†
        if paper_id is not None:
            paper_id = paper_id.split(':')[-1]
        
        shieldio_data = {
            "schemaVersion": 1,
            "label": "citations",
            # å˜æˆå­—ç¬¦ä¸²
            "message": f"{citations}",
        }
        
        # ä¿å­˜ä¸ºjsonæ–‡ä»¶
        with open(f'results/selected_pubs/{paper_id}.json', 'w') as file:
            json.dump(shieldio_data, file)
        

    print("å·²æˆåŠŸæå–å¹¶ä¿å­˜æ‰€é€‰å‡ºç‰ˆç‰©çš„å¼•ç”¨æ•°æ®ã€‚")
    
    return

def long_id_citations():
    
    global count
    count = 0
    
    # long_ids
    long_ids = read_long_ids_2024_before('results/all_publications.csv')
    # print(long_ids)
    
    long_ids.append('OlLjVUcAAAAJ:RYcK_YlVTxYC', 'OlLjVUcAAAAJ:lSLTfruPkqcC', 'OlLjVUcAAAAJ:_Qo2XoVZTnwC',
                    'OlLjVUcAAAAJ:yD5IFk8b50cC')
    
    json_file = f'results/gs_data.json'
    selected_data = json.load(open(json_file, 'r'))
    
    for long_id in long_ids:
        citations, paper_id = find_citations_by_long_id(selected_data, long_id)
        
        if paper_id is not None:
            paper_id = paper_id.split(':')[-1]
            
        # if paper_id == 'yD5IFk8b50cC':
        #     print(f"è®ºæ–‡ {paper_id} çš„å¼•ç”¨æ•°ä¸º {citations}")
        
        shieldio_data = {
            "schemaVersion": 1,
            "label": "citations",
            # å˜æˆå­—ç¬¦ä¸²
            "message": f"{citations}",
        }
        
        # print(f"è®ºæ–‡ {paper_id} çš„å¼•ç”¨æ•°ä¸º {citations}")
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨selected_pubsæ–‡ä»¶å¤¹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        import os
        if not os.path.exists('results/selected_pubs'):
            os.makedirs('results/selected_pubs')
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨paper_id.jsonæ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        # if not os.path.exists(f'results/selected_pubs/{paper_id}.json'):
        #     os.mknod(f'results/selected_pubs/{paper_id}.json')
    
        try:
            
            with open(f'results/selected_pubs/{paper_id}.json', 'w') as file:
                json.dump(shieldio_data, file)
                count += 1
        
        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            print(f"è®ºæ–‡ {paper_id} çš„å¼•ç”¨æ•°ä¸º {citations}")
            continue

    
    # print("å·²æˆåŠŸæå–å¹¶ä¿å­˜æ‰€é€‰å‡ºç‰ˆç‰©çš„å¼•ç”¨æ•°æ®ã€‚")
    print(f"å…±æœ‰ {count} ç¯‡è®ºæ–‡çš„å¼•ç”¨æ•°æ®å·²ä¿å­˜ã€‚")
    
    return

if __name__ == '__main__':
    # title_citations()
    long_id_citations()